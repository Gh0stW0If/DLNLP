{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c1d585",
   "metadata": {},
   "source": [
    "# 新闻数据预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d5aba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import jieba\n",
    "import opencc\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "539e2d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“我知道，我不是因为偶然才来到这个世界，我是为了践行一个平凡、美丽、无私的梦想而来的；我是为了通过各种苦乐逆顺的体验来历练自己而来的，并由此完善，成长而提升……”金华市环城小学校训，没有一个字和学习有关，却让学生、家长和老师都掉下泪来。校训原文： 世界因我多温暖 我知道，我不是因为偶然才来到这个世界，我是为了践行一个平凡、美丽、无私的梦想而来的;我是为了通过各种苦乐逆顺的体验来历练自己而来的，并由此完善，成长而提升。 我深深地知道，改变这个世界的力量来自太阳，来自人类心灵深处的温度。我，要让世界因我而多温暖。 我知道，我所有的长处都源自父母祖宗的优秀，源自华夏千年文明的积淀。但它不是我炫耀和自私的资本，它是我赖以成长并服务人类的工具，它是我生命的伟大、美好和无私的工具。 我知道，我的缺点与不足不是我的自愿，那是因为我是从有缺点和不足的爸爸妈妈而来，选择这样的爸爸妈妈是我的自愿。对于这些缺陷，我全然接受，并通过今生的感恩、忍受和努力来弥补。 我想对爸爸妈妈说，我愿意从今天开始，不再用完美要求你们，也请你们不再用完美苛求于我，我是你们的一部分，我们是一个整体，让我们一起改变，用爱让家里充满温暖，以影响世界。 从今天起，我将高高地放飞自己的梦想，积极乐观地生活和学习。 命运从来没有规定我此生将是什么?国家没有规定我，父母没有规定我，老师也是一样。一切万物都没有规定我必须是什么样的人，大家把一切主动权交给我，让我自己决定自己的梦想，然后慈悲无私地帮助我，成就我。 因此，我必须让我自己成为一颗最圆润的种子，让周边的世界因我的成长而温暖。 我知道，生命是人世间最美丽的奇迹，读书是人世间最享受的愉悦。 老师对我说，曾经有一个善人，在春天的时候特别给两个乞丐一间破房和一块空地。到了秋天，一个懒惰的乞丐贫病而死，而另一个勤奋的乞丐却富裕安乐。 在宇宙中，每一个灵魂都是乞丐，四处漂泊。父母就是善人，给了属于我的一间破房和广袤无垠的空地，那间破房就是我不完美的身体，而那块空地就是我无边的心灵。我坚信，只要用勤劳播撒智慧与爱的种子，就一定会有硕果累累的明天。 从这一刻起，我要用无限的信心走向未来。 我知道，生命中最珍贵最强大的就是灵魂。环城小学是我人生的第一母校，母校给我的最大眷顾是把我放在春天里，给我规矩，给我阳光，给我一颗春天般温暖柔软的灵魂，去温暖属于我们的世界。 谨此践行我们的校训：世界因我多温暖。 一位刘老师说，她对校训中关于缺点的两段感触颇深：“别说普通家长，就是我们这些当老师的，很多时候也会苛责孩子的不完美，希望他们做得更好，其实我们都挺缺少承认自己和对方都不完美的勇气。”校训文的主要作者是校长俞正强，初稿是他寒假里写好的。俞正强说，写这个文章，主要是想告诉孩子三件事。一、孩子们都是带着使命而来，生活不仅有顺境，也有辛苦挫折，但是这能让我们成长。二、我们的优缺点来自父母，我们都是不完美的人，生活中不应有太多指责、抱怨，只有家庭温暖才能温暖世界。三、孩子最重要的并不是学习多少知识，而是有一个温暖和柔软的灵魂。他说，这篇校训文不仅是为了影响孩子们，也是为了影响家长和老师。 文章来源：行知父母微学堂 教师吧 龙乡教育，向您约稿：如果您有好的文章、好的事例、好的新闻线索，请发至pyxjyxxbs@163.com 微信ID：puyangxianjiaoyu 长按左侧二维码关注\n"
     ]
    }
   ],
   "source": [
    "#读取json文件获取数据\n",
    "def read_json(file_path):\n",
    "    content = []\n",
    "    cnt = 0 \n",
    "    limit = 10000\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            cnt += 1\n",
    "            if cnt > limit:\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            content.append(data['content'])\n",
    "            \n",
    "\n",
    "    return content\n",
    "\n",
    "content = read_json('news2016zh_valid.json')\n",
    "print(content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d6c8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comma_list  = [\n",
    "    '3002', 'FF1F', 'FF01', '3010', '3011', 'FF0C', '3001', 'FF1B',\n",
    "    'FF1A', '300C', '300D', '300E', '300F', '2019', '201C', '201D',\n",
    "    '2018', 'FF08', 'FF09', '3014', '3015', '2026', '2013', 'FF0E',\n",
    "    '2014', '300A', '300B', '3008', '3009'\n",
    "]\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "        converter = opencc.OpenCC('t2s.json')\n",
    "        #简体转繁体\n",
    "        text = converter.convert(text)\n",
    "        #分词\n",
    "    \n",
    "        #保留汉字\\u4e00-\\u9fa5和标点\n",
    "        text = re.sub(r'[^\\u4e00-\\u9fa5' + ''.join([chr(int(i, 16)) for i in comma_list]) + ']+', ' ', text)\n",
    "        words = list(jieba.cut(text))\n",
    "        #去除停用词\n",
    "        return words\n",
    "\n",
    "def getvocab(paragraphs):\n",
    "    all_words = []\n",
    "    for text in paragraphs:\n",
    "        words = preprocess_text(text)#保留停用词\n",
    "        # print(words[:10])  # 打印前10个分词\n",
    "        #去除空字符串\n",
    "        words = [word for word in words if word !='']\n",
    "        #添加EOS和BOS\n",
    "        words = ['<BOS>'] + words + ['<EOS>']\n",
    "        #去除空段落\n",
    "        if len(words) < 1:\n",
    "            continue\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    #去除空格\n",
    "    all_words = [word for word in all_words if word != ' ']\n",
    "    \n",
    "    #建立词表\n",
    "    vocab = sorted(set(all_words))\n",
    "    #保存json词表\n",
    "    with open('vocab.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(vocab, f, ensure_ascii=False, indent=4)\n",
    "    return all_words,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62fe1a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n"
     ]
    }
   ],
   "source": [
    "all_words,vocab = getvocab(content)\n",
    "print(all_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63f62779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BOS>', '“', '我', '知道', '，', '我', '不是', '因为', '偶然', '才']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7802bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据集\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encoded_texts, length):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        for i in range(len(encoded_texts)-length):\n",
    "            if len(encoded_texts) > length:\n",
    "                input_seq = encoded_texts[i:i+length]\n",
    "\n",
    "                # print(input_seq)\n",
    "                target_seq = encoded_texts[i+length]\n",
    "                # print(target_seq)\n",
    "\n",
    "                self.inputs.append(input_seq)\n",
    "                self.targets.append(target_seq)\n",
    "        self.inputs = torch.tensor(self.inputs, dtype=torch.long)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "    \n",
    "#transformer所需数据集\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, encoded_texts, length,shift):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        for i in range(len(encoded_texts)-length):\n",
    "            if len(encoded_texts) > length:\n",
    "                input_seq = encoded_texts[i:i+length]\n",
    "\n",
    "                \n",
    "                target_seq = encoded_texts[i+shift:i+length+shift]\n",
    "                #添加eos\n",
    "\n",
    "                # 这里的shift是为了让target_seq比input_seq向后滑动shift\n",
    "                #检查长度，如果长度不够就跳过\n",
    "                if len(target_seq) != length:\n",
    "                    continue\n",
    "                self.inputs.append(input_seq)\n",
    "                self.targets.append(target_seq)\n",
    "        self.inputs = torch.tensor(self.inputs, dtype=torch.long)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26b1bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "        out, hidden = self.lstm(x, hidden)  # out: (batch_size, seq_len, hidden_dim)\n",
    "        out = self.fc(out[:, -1, :])  # 只用最后一个时间步输出\n",
    "        return out\n",
    "    \n",
    "#定义transformer模型\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)].to(x.device)\n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, num_heads=4, hidden_dim=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=1)#一层decoder\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        # 下三角 mask (tgt_len, tgt_len)\n",
    "        mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "        return mask.to(next(self.parameters()).device)\n",
    "    \n",
    "    def forward(self,x,tgt):\n",
    "        # print(f\"Received args: x shape={x.shape}, tgt shape={tgt.shape}\")\n",
    "        # x shape: (batch, seq_len)\n",
    "        # tgt shape: (batch, seq_len)\n",
    "        x = self.embedding(x)                     # -> (batch, seq_len, embed_dim)\n",
    "        x = self.pos_encoder(x)                   # 加位置编码\n",
    "        x = x.transpose(0, 1)                     # -> (seq_len, batch, embed_dim)\n",
    "        memory = self.transformer_encoder(x)           # -> (seq_len, batch, embed_dim)\n",
    "        tgt = self.embedding(tgt)                 # -> (batch, seq_len, embed_dim)\n",
    "        tgt = self.pos_encoder(tgt)               # 加位置编码\n",
    "        tgt = tgt.transpose(0, 1)                 # -> (seq_len, batch, embed_dim)\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(0))\n",
    "        x = self.transformer_decoder(tgt, memory =memory,tgt_mask = tgt_mask)        # -> (seq_len, batch, embed_dim)\n",
    "        x = self.fc(x[-1])                        # 只取最后一个时间步的输出\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4795d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练代码\n",
    "def train_model(model,vocab_size,dataloader,device, criterion, optimizer, num_epochs=10):\n",
    "    \n",
    "    model.to(device)\n",
    "    #模型名\n",
    "    model_name = type(model).__name__\n",
    "    print(f\"Training {model_name} model with {num_epochs} epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        time_bar = tqdm.tqdm(total=len(dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\")\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        best_loss = float('inf')\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if model_name == 'LSTMModel':\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            else:\n",
    "                outputs = model(inputs,targets)\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets[:,-1])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            time_bar.update(1)\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), model_name+'_best_model.pth')\n",
    "        print(\"*\" * 20+'正在训练'+model_name+\"*\" * 20)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b9e8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxiaofei/anaconda3/envs/NLP/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "# idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "# print(encoded_texts[:10])\n",
    "special_tokens = ['<PAD>', '<UNK>', '<BOS>', '<EOS>']\n",
    "special_tokens_add =['<PAD>', '<UNK>']\n",
    "vocab = special_tokens_add + vocab\n",
    "# 重新编号\n",
    "word2idx = {token: idx for idx, token in enumerate(special_tokens)}\n",
    "for word in vocab:\n",
    "    if word not in word2idx:\n",
    "        word2idx[word] = len(word2idx)\n",
    "\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "#把special_token添加到vocab前\n",
    "\n",
    "encoded_texts = [word2idx[word] for word in all_words]\n",
    "dataset = TextDataset(encoded_texts, length=8)\n",
    "batch_size = 512\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "transformer_dataset = TransformerDataset(encoded_texts, length=8,shift=1)\n",
    "transformer_dataloader = DataLoader(transformer_dataset, batch_size=batch_size, shuffle=True)\n",
    "#设置设备为GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#定义模型参数\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "\n",
    "#定义模型\n",
    "model = LSTMModel(len(vocab), embedding_dim, hidden_dim, num_layers).to(device)\n",
    "model2 = TransformerModel(len(vocab), embed_dim=embedding_dim, num_heads=4, hidden_dim=hidden_dim, num_layers=num_layers).to(device)\n",
    "#定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24640652",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(vocab, open('vocab2.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "568fafc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTMModel model with 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████▉| 12110/12111 [08:35<00:00, 16.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [1/10], Loss: 7.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 12111/12111 [08:36<00:00, 23.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [2/10], Loss: 6.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 12111/12111 [08:51<00:00, 22.78batch/s]\n",
      "Epoch 3/10: 100%|█████████▉| 12109/12111 [08:50<00:00, 21.08batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [3/10], Loss: 6.3748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 12111/12111 [08:51<00:00, 22.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [4/10], Loss: 6.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 12111/12111 [08:51<00:00, 22.78batch/s]\n",
      "Epoch 5/10: 100%|█████████▉| 12110/12111 [08:52<00:00, 20.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [5/10], Loss: 5.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 12111/12111 [08:53<00:00, 22.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [6/10], Loss: 5.7752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 12111/12111 [04:36<00:00, 43.76batch/s]\n",
      "Epoch 7/10: 100%|█████████▉| 12109/12111 [04:21<00:00, 48.53batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [7/10], Loss: 5.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 12111/12111 [04:22<00:00, 46.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [8/10], Loss: 5.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 12111/12111 [04:21<00:00, 46.23batch/s]\n",
      "Epoch 9/10: 100%|█████████▉| 12110/12111 [04:20<00:00, 48.32batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [9/10], Loss: 5.4687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 12111/12111 [04:21<00:00, 46.24batch/s]\n",
      "Epoch 10/10: 100%|██████████| 12111/12111 [04:21<00:00, 46.24batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练LSTMModel********************\n",
      "Epoch [10/10], Loss: 5.3973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, len(vocab), dataloader, device, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5c1631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerModel model with 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████▉| 12108/12111 [05:43<00:00, 34.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [1/10], Loss: 12.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 12111/12111 [05:44<00:00, 35.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [2/10], Loss: 12.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 12111/12111 [05:44<00:00, 35.13batch/s]\n",
      "Epoch 3/10: 100%|█████████▉| 12110/12111 [05:43<00:00, 35.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [3/10], Loss: 12.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 12111/12111 [05:43<00:00, 35.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [4/10], Loss: 12.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 12111/12111 [05:57<00:00, 33.88batch/s]\n",
      "Epoch 5/10: 100%|█████████▉| 12110/12111 [05:53<00:00, 29.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [5/10], Loss: 12.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 12111/12111 [05:54<00:00, 34.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [6/10], Loss: 12.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 12111/12111 [05:50<00:00, 34.54batch/s]\n",
      "Epoch 7/10: 100%|█████████▉| 12108/12111 [05:46<00:00, 35.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [7/10], Loss: 12.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 12111/12111 [05:47<00:00, 34.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [8/10], Loss: 12.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 12111/12111 [05:50<00:00, 34.53batch/s]\n",
      "Epoch 9/10: 100%|██████████| 12111/12111 [05:43<00:00, 18.02batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [9/10], Loss: 12.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 12111/12111 [05:43<00:00, 35.25batch/s]\n",
      "Epoch 10/10: 100%|██████████| 12111/12111 [05:59<00:00, 33.73batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************正在训练TransformerModel********************\n",
      "Epoch [10/10], Loss: 12.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model2, len(vocab), transformer_dataloader, device, criterion, optimizer, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
